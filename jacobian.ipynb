{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "function nabla(f, x::Float64, delta::Float64)\n",
        "\n",
        "  ## differentiation of holomorphic functions in a single complex variable applied \n",
        "  ## to real-valued functions in a single variable using the Cauchy Integral Formula\n",
        "\n",
        "  ## f:= the function to be differentiated\n",
        "  ## x:= where the derivative is evaluated\n",
        "  ## delta:= the sampling frequency\n",
        "\n",
        "  N = round(Int,2*pi/delta)\n",
        "  thetas = vcat(1:N)*delta\n",
        "\n",
        "  ## collect arguments and rotations: \n",
        "  rotations = map(theta -> exp(-im*theta),thetas)\n",
        "  arguments = x .+ conj.(rotations)  \n",
        "\n",
        "  ## calculate expectation: \n",
        "  expectation = 1.0/N*real(sum(map(f,arguments).*rotations))\n",
        "\n",
        "  return expectation\n",
        "\n",
        "end\n",
        "\n",
        "function partial_nabla(f, i::Int64, X::Array{Float64,1},delta::Float64)\n",
        "\n",
        "  ## partial differentiation of holomorphic functions in a single complex variable applied \n",
        "  ## to real-valued functions in a single variable using the Cauchy Integral Formula\n",
        "\n",
        "  ## f:= the function to be differentiated\n",
        "  ## i:= partial differentiation with respect to this index\n",
        "  ## X:= where the partial derivative is evaluated\n",
        "  ## delta:= the sampling frequency\n",
        "\n",
        "  N = length(X)\n",
        "\n",
        "  kd(i,n) = [j==i for j in 1:n]\n",
        "\n",
        "  f_i = x -> f(x*kd(i,N) .+ X.*(ones(N)-kd(i,N)))\n",
        "\n",
        "  return nabla(f_i,X[i],delta)\n",
        "\n",
        "end\n",
        "\n\n",
        "function jacobian(f,X::Array{Float64,1},case::Int64,delta::Float64)\n",
        "    \n",
        "    N = Int(length(X))\n",
        "    \n",
        "    if case == 1\n",
        "    \n",
        "        ## initialise jacobian: \n",
        "        J = zeros(N,N)\n",
        "\n",
        "        for i = 1:N\n",
        "\n",
        "            f_i(x) = f(x)[i]\n",
        "            J[i,:] = [partial_nabla(f_i,j,X,delta) for j=1:N]\n",
        "\n",
        "        end\n",
        "\n",
        "        return J\n",
        "        \n",
        "    else\n",
        "            \n",
        "       return [partial_nabla(f,j,X,delta) for j=1:N]\n",
        "\n",
        "   end\n",
        "        \n",
        "end"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": [
              "jacobian (generic function with 1 method)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We now define the method for gradient updates: "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "function gradient_updates(W::Array{Float64,2},X::Array{Float64,1},case::Int64,delta::Float64)\n",
        "\n",
        "\trelu(x) = log.(1 .+ exp.(x))\n",
        "\n",
        "\tif case == 1\n",
        "\n",
        "\t\tg(Z) = relu([sum(W[1,:].*Z) ,sum(W[2,:].*Z),sum(W[3,:].*Z)] .+W[4,:])\n",
        "\n",
        "\t\treturn jacobian(g,X,1,delta)\n",
        "\n",
        "\telse \n",
        "\n",
        "\t\t## there is probably a way to simplify this: \n",
        "\t\tg_1(Z) = relu([sum(Z.*X) ,sum(W[2,:].*X),sum(W[3,:].*X)] .+W[4,:])\n",
        "\n",
        "\t\tg_2(Z) = relu([sum(W[1,:].*X) ,sum(Z.*X),sum(W[3,:].*X)] .+W[4,:])\n",
        "\n",
        "\t\tg_3(Z) = relu([sum(W[1,:].*X) ,sum(W[2,:].*X),sum(Z.*X)] .+W[4,:])\n",
        "\n",
        "\t\tg_4(Z) = relu([sum(W[1,:].*X) ,sum(W[2,:].*X),sum(W[3,:].*X)] .+Z)\n",
        "\n",
        "\t\treturn [jacobian(g_1,W[1,:],1,delta), jacobian(g_2,W[2,:],1,delta),jacobian(g_3,W[3,:],1,delta),jacobian(g_4,W[4,:],1,delta)]\n",
        "\n",
        "\tend\n",
        "\nend"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": [
              "gradient_updates (generic function with 1 method)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing jacobian on gradient descent: "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "function gradient_descent_(f)\n",
        "    \n",
        "    x = ones(3)\n",
        "\n",
        "    L(x) = sum((f(x) .- zeros(3)).^2)\n",
        "\n",
        "    alpha = 0.1\n",
        "\n",
        "    for i = 1:100\n",
        "        \n",
        "            #update = alpha*2*(f(x) .- zeros(3))'*jacobian(f,x,1,2*pi/10)\n",
        "            update = alpha*jacobian(L,x,2,2*pi/10)'*jacobian(f,x,1,2*pi/10)\n",
        "\n",
        "            x -= update'      \n",
        "\n",
        "    end\n",
        "\n",
        "    return x\n",
        "    \n",
        "end"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": [
              "gradient_descent_ (generic function with 1 method)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## test it on a linear function: \n",
        "W = rand(4,3)\n",
        "\n",
        "f(Z) = [sum(W[1,:].*Z) ,sum(W[2,:].*Z),sum(W[3,:].*Z)] .+W[4,:]\n",
        "\n",
        "## the result looks reasonable: \n",
        "x_ = gradient_descent_(f);\n",
        "\n",
        "L(x) = (zeros(3) .- f(x)).^2\n",
        "\n",
        "#L(x_)\n",
        "\nf(x_)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": [
              "3-element Array{Float64,1}:\n",
              " -0.0900236607273408\n",
              " -0.2360883810597736\n",
              "  0.4642845054045776"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 21,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test it on learning the identity function: "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "using Distributions\n",
        "\n",
        "function GD(x)\n",
        "    \n",
        "    ## delta: \n",
        "    delta = 2*pi/100\n",
        "    \n",
        "    ## We define a linear function: \n",
        "    #W = rand(3,2)\n",
        "    \n",
        "    ## we use Xavier initialisation: \n",
        "    W = rand(Uniform(-1/sqrt(3),1/sqrt(3)),(4,3))\n",
        "\n",
        "    f(Z) = [sum(W[1,:].*Z) ,sum(W[2,:].*Z),sum(W[3,:].*Z)] .+W[4,:]\n",
        "\n",
        "    ## our squared loss: \n",
        "    L(x) = sum((x .- f(x)).^2)\n",
        "\n",
        "    alpha = 0.1\n",
        "\n",
        "    for i = 1:50\n",
        "\n",
        "    \tX = 10*rand(3)\n",
        "    \n",
        "        ## gradient updates:         \n",
        "        dL = alpha*jacobian(L,X,2,2*pi/100)'\n",
        "    \n",
        "        dW_ = gradient_updates(W,X,2,delta)\n",
        "    \n",
        "        W[1,:] -= (alpha*dL*dW_[1])'\n",
        "\n",
        "\t\tW[2,:] -= (alpha*dL*dW_[2])'\n",
        "\n",
        "\t\tW[3,:] -= (alpha*dL*dW_[3])'\n",
        "\n",
        "\t\tW[4,:] -= (alpha*dL*dW_[4])'\n",
        "\n",
        "    end\n",
        "\n",
        "    return W\n",
        "    \n",
        "end"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 33,
          "data": {
            "text/plain": [
              "GD (generic function with 1 method)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 33,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W_ = GD(zeros(3))\n",
        "\n",
        "f(Z) = [sum(W_[1,:].*Z) ,sum(W_[2,:].*Z),sum(W_[3,:].*Z)] .+W_[4,:]\n",
        "\nf(3*ones(3))"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 35,
          "data": {
            "text/plain": [
              "3-element Array{Float64,1}:\n",
              " -6.130651445471345\n",
              " -6.968973297073677\n",
              " -6.193575809252167"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 35,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now, let's try batch gradients: "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "function batch_GD(x)\n",
        "    \n",
        "    ## delta: \n",
        "    delta = 2*pi/100\n",
        "    \n",
        "    ## We define a linear function: \n",
        "    W = rand(Uniform(-1/sqrt(3),1/sqrt(3)),(4,3))\n",
        "\n",
        "    f(Z) = [sum(W[1,:].*Z) ,sum(W[2,:].*Z),sum(W[3,:].*Z)] .+W[4,:]\n",
        "\n",
        "    ## our squared loss: \n",
        "    L(x) = sum((x .- f(x)).^2)\n",
        "\n",
        "    alpha = 0.01\n",
        "\n",
        "    for i = 1:100\n",
        "        \n",
        "        W_ = rand(Uniform(-1/sqrt(3),1/sqrt(3)),(4,3))\n",
        "        \n",
        "        for j = 1:10\n",
        "\n",
        "            X = 10*rand(3)\n",
        "\n",
        "            ## gradient updates:         \n",
        "            dL = alpha*jacobian(L,X,2,delta)'\n",
        "\n",
        "            dW_ = gradient_updates(W,X,2,delta)\n",
        "            \n",
        "            W_[1,:] += (alpha*dL*dW_[1])'\n",
        "            \n",
        "            W_[2,:] += (alpha*dL*dW_[2])'\n",
        "            \n",
        "            W_[3,:] += (alpha*dL*dW_[3])'\n",
        "            \n",
        "            W_[4,:] += (alpha*dL*dW_[4])'\n",
        "            \n",
        "        end\n",
        "        \n",
        "        W[1,:] -= 1/10*W_[1,:]\n",
        "\n",
        "        W[2,:] -= 1/10*W_[2,:]\n",
        "\n",
        "        W[3,:] -= 1/10*W_[3,:]\n",
        "\n",
        "        W[4,:] -= 1/10*W_[4,:]\n",
        "\n",
        "    end\n",
        "\n",
        "    return W\n",
        "    \n",
        "end"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 53,
          "data": {
            "text/plain": [
              "batch_GD (generic function with 1 method)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 53,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W_ = batch_GD(zeros(3));\n",
        "\nf(Z) = [sum(W_[1,:].*Z) ,sum(W_[2,:].*Z),sum(W_[3,:].*Z)] .+W_[4,:]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 54,
          "data": {
            "text/plain": [
              "f (generic function with 1 method)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 54,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f(3*ones(3))"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 57,
          "data": {
            "text/plain": [
              "3-element Array{Float64,1}:\n",
              " 2.4765392348267405 \n",
              " 2.723247046320566  \n",
              " 0.21503815400008325"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 57,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L(x) = sum((x .- f(x)).^2)\n",
        "\n",
        "N = 100\n",
        "\n",
        "X = 10*rand(N,3)\n",
        "\nsum([L(X[i,:]) for i =1:N])/N"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = rand(3)\n",
        "\n",
        "W = rand(4,3)\n",
        "\n",
        "f(Z) = [sum(W[1,:].*Z) ,sum(W[2,:].*Z),sum(W[3,:].*Z)] .+W[4,:]\n",
        "\n",
        "## our squared loss: \n",
        "L(x) = sum((x .- f(x)).^2)\n",
        "        \n",
        "## update functions: \n",
        "f_1(Z) = [sum(Z.*X) ,sum(W[2,:].*X),sum(W[3,:].*X)] .+W[4,:]\n",
        "\n",
        "f_2(Z) = [sum(W[1,:].*X) ,sum(Z.*X),sum(W[3,:].*X)] .+W[4,:]\n",
        "\n",
        "f_3(Z) = [sum(W[1,:].*X) ,sum(W[2,:].*X),sum(Z.*X)] .+W[4,:]\n",
        "\n",
        "f_4(Z) = [sum(W[1,:].*X) ,sum(W[2,:].*X),sum(W[3,:].*X)] .+Z\n",
        "\n",
        "## gradient updates: \n",
        "dL = alpha*jacobian(L,X,2,2*pi/10)'\n",
        "\n",
        "#[partial_nabla(L,j,X,delta) for j=1:3]\n",
        "\n",
        "dW_ = [jacobian(f_1,W[1,:],1,delta), jacobian(f_2,W[2,:],1,delta),jacobian(f_3,W[3,:],1,delta),jacobian(f_4,W[4,:],1,delta)]\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(alpha*dL*dW_[1]*dW_[1])'"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W[1,:]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "julia-1.0"
    },
    "language_info": {
      "file_extension": ".jl",
      "name": "julia",
      "mimetype": "application/julia",
      "version": "1.0.0"
    },
    "kernelspec": {
      "name": "julia-1.0",
      "language": "julia",
      "display_name": "Julia 1.0.0"
    },
    "nteract": {
      "version": "0.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}